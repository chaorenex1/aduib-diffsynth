"""
æ–‡ç”Ÿå›¾åŠŸèƒ½æµ‹è¯•è„šæœ¬

ä½¿ç”¨ç¤ºä¾‹ï¼š
python test_text_to_image.py
"""
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_simple_generation():
    """æµ‹è¯•ç®€å•çš„å›¾åƒç”Ÿæˆ"""
    print("\n=== æµ‹è¯• 1: ç®€å•å›¾åƒç”Ÿæˆ ===")

    try:
        from diffsynths.text_to_image import generate_image

        print("æ­£åœ¨ç”Ÿæˆå›¾åƒ...")
        image_path = generate_image(
            prompt="a beautiful sunset over mountains, highly detailed, 4k",
            negative_prompt="low quality, blurry, deformed",
            model_type="sd",
            width=512,
            height=512,
            num_inference_steps=20,
            guidance_scale=7.5,
            seed=42,
        )

        print(f"âœ… å›¾åƒç”ŸæˆæˆåŠŸï¼")
        print(f"   ä¿å­˜è·¯å¾„: {image_path}")
        return True

    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        print("   è¯·å®‰è£… diffsynth-engine: uv pip install diffsynth-engine")
        return False
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        return False


def test_batch_generation():
    """æµ‹è¯•æ‰¹é‡ç”Ÿæˆ"""
    print("\n=== æµ‹è¯• 2: æ‰¹é‡å›¾åƒç”Ÿæˆ ===")

    try:
        from diffsynths.text_to_image import get_generator

        generator = get_generator()
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        generator.load_model("sd")

        prompts = [
            "a red apple on a table",
            "a blue car in the street",
            "a green tree in the park",
        ]

        print(f"æ­£åœ¨æ‰¹é‡ç”Ÿæˆ {len(prompts)} å¼ å›¾åƒ...")
        image_paths = generator.batch_generate(
            prompts=prompts,
            width=512,
            height=512,
            num_inference_steps=20,
            guidance_scale=7.5,
            seed=42,
        )

        print(f"âœ… æ‰¹é‡ç”ŸæˆæˆåŠŸï¼")
        for i, path in enumerate(image_paths, 1):
            print(f"   å›¾åƒ {i}: {path}")

        # å¸è½½æ¨¡å‹
        print("æ­£åœ¨å¸è½½æ¨¡å‹...")
        generator.unload_model()

        return True

    except Exception as e:
        print(f"âŒ æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
        return False


def test_model_info():
    """æµ‹è¯•æ¨¡å‹ä¿¡æ¯"""
    print("\n=== æµ‹è¯• 3: æ¨¡å‹ä¿¡æ¯ ===")

    try:
        import torch
        print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
        print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
            print(f"GPU è®¾å¤‡: {torch.cuda.get_device_name(0)}")
            print(f"GPU æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        return True
    except Exception as e:
        print(f"âŒ è·å–ä¿¡æ¯å¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 60)
    print("æ–‡ç”Ÿå›¾åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)

    results = []

    # æµ‹è¯•æ¨¡å‹ä¿¡æ¯
    results.append(("æ¨¡å‹ä¿¡æ¯", test_model_info()))

    # æµ‹è¯•ç®€å•ç”Ÿæˆ
    results.append(("ç®€å•ç”Ÿæˆ", test_simple_generation()))

    # æµ‹è¯•æ‰¹é‡ç”Ÿæˆ
    # results.append(("æ‰¹é‡ç”Ÿæˆ", test_batch_generation()))
    # æ³¨æ„ï¼šæ‰¹é‡ç”Ÿæˆæµ‹è¯•å·²æ³¨é‡Šï¼Œå› ä¸ºå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{name}: {status}")

    total = len(results)
    passed = sum(1 for _, success in results if success)
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")


if __name__ == "__main__":
    main()

